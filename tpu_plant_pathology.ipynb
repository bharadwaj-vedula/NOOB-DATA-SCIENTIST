{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tpu_plant_pathology",
      "provenance": [],
      "authorship_tag": "ABX9TyNfUVBCYkUd+cQUtc50/P2e"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktUW9Q6emOfS",
        "colab_type": "code",
        "outputId": "445de87e-72bd-4e6c-ea1f-2b8c691d930b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "%tensorflow_version 2.x \n",
        "!pip install -q efficientnet\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "\n",
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from IPython.display import SVG\n",
        "import efficientnet.tfkeras as efn\n",
        "from keras.utils import plot_model\n",
        "import tensorflow.keras.layers as L\n",
        "from keras.utils import model_to_dot\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model,load_model\n",
        "\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.cm as cm\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tqdm.pandas()\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcijPZbSm8lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files \n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-auNiw-fm9Nb",
        "colab_type": "code",
        "outputId": "6b815817-7e83-4043-a483-15d3455c94f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6\n",
        "!kaggle -v\n",
        "!mkdir -p ~/.kaggle \n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling kaggle-1.5.6:\n",
            "  Successfully uninstalled kaggle-1.5.6\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/2e/df11ea7e23e7e761d484ed3740285a34e38548cf2bad2bed3dd5768ec8b9/pip-20.1-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 3.3MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.1\n",
            "Collecting kaggle==1.5.6\n",
            "  Downloading kaggle-1.5.6.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2020.4.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-py3-none-any.whl size=72859 sha256=de906f8c2dc1ac52018d052131df515310addcf8e3bd3034f06d656d726f40a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/3e/ff/77407ebac3ef71a79b9166a8382aecf88415a0bcbe3c095a01\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/api/kaggle_api_extended.py\", line 149, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGtCEw1zT2jb",
        "colab_type": "code",
        "outputId": "6aee3e48-fb75-465b-dc44-5041f38b31f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!kaggle competitions download -c plant-pathology-2020-fgvc7"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading plant-pathology-2020-fgvc7.zip to /content\n",
            "100% 776M/779M [00:06<00:00, 147MB/s]\n",
            "100% 779M/779M [00:06<00:00, 117MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hmFHNdET46i",
        "colab_type": "code",
        "outputId": "3e085913-da2d-47c1-b1d7-df6b8a4210b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name=\"plant-pathology-2020-fgvc7.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFmeUET2nLjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 20\n",
        "SAMPLE_LEN = 100\n",
        "IMAGE_PATH = \"/content/images\"\n",
        "TEST_PATH = \"/content/test.csv\"\n",
        "TRAIN_PATH = \"/content/train.csv\"\n",
        "SUB_PATH = \"/content/sample_submission.csv\"\n",
        "\n",
        "sub = pd.read_csv(SUB_PATH)\n",
        "test_data = pd.read_csv(TEST_PATH)\n",
        "train_data = pd.read_csv(TRAIN_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36K2VvYwnkID",
        "colab_type": "code",
        "outputId": "82e0c956-bd52-4898-ebf7-6195ea04b2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.68.202.74:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.68.202.74:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Ap2m-qnleQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GCS_DS_PATH='gs://kds-44c8a6f93070fa89189427ff10c4c0530ab3f532ac92907ab3c2bb58'\n",
        "def format_path(st):\n",
        "    return GCS_DS_PATH + '/images/' + st + '.jpg'\n",
        "\n",
        "test_paths = test_data.image_id.apply(format_path).values\n",
        "train_paths = train_data.image_id.apply(format_path).values\n",
        "\n",
        "train_labels = train_data.loc[:, 'healthy':].values\n",
        "train_paths, valid_paths, train_labels, valid_labels =train_test_split(train_paths, train_labels, test_size=0.15, random_state=2020)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EThlFJnso695",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_image(filename, label=None, image_size=(256, 256)):\n",
        "    bits = tf.io.read_file(filename)\n",
        "    image = tf.image.decode_jpeg(bits, channels=3)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    image = tf.image.resize(image, image_size)\n",
        "    \n",
        "    if label is None:\n",
        "        return image\n",
        "    else:\n",
        "        return image, label\n",
        "\n",
        "def data_augment(image, label=None):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    \n",
        "    if label is None:\n",
        "        return image\n",
        "    else:\n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idq3crZ1pApF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((train_paths, train_labels))\n",
        "    .map(decode_image, num_parallel_calls=AUTO)\n",
        "    .cache()\n",
        "    .map(data_augment, num_parallel_calls=AUTO)\n",
        "    .repeat()\n",
        "    .shuffle(512)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "valid_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((valid_paths, valid_labels))\n",
        "    .map(decode_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .cache()\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "test_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices(test_paths)\n",
        "    .map(decode_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_kNy12ypIDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_lrfn(lr_start=0.00001, lr_max=0.00005, \n",
        "               lr_min=0.00001, lr_rampup_epochs=5, \n",
        "               lr_sustain_epochs=0, lr_exp_decay=.8):\n",
        "    lr_max = lr_max * strategy.num_replicas_in_sync\n",
        "\n",
        "    def lrfn(epoch):\n",
        "        if epoch < lr_rampup_epochs:\n",
        "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
        "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
        "            lr = lr_max\n",
        "        else:\n",
        "            lr = (lr_max - lr_min) *\\\n",
        "                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n",
        "                                - lr_sustain_epochs) + lr_min\n",
        "        return lr\n",
        "    return lrfn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6p0v3_TqaOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrfn = build_lrfn()\n",
        "STEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIVAY33bq3DS",
        "colab_type": "code",
        "outputId": "b2dac4fa-1f65-408c-9952-181293095942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "with strategy.scope():\n",
        "    model = tf.keras.Sequential([DenseNet121(input_shape=(512, 512, 3),\n",
        "                                             weights='imagenet',\n",
        "                                             include_top=False),\n",
        "                                 L.GlobalAveragePooling2D(),\n",
        "                                 L.Dense(train_labels.shape[1],\n",
        "                                         activation='softmax')])\n",
        "        \n",
        "    model.compile(optimizer='adam',\n",
        "                  loss = 'categorical_crossentropy',\n",
        "                  metrics=['categorical_accuracy'])\n",
        "    model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "densenet121 (Model)          (None, 16, 16, 1024)      7037504   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 4100      \n",
            "=================================================================\n",
            "Total params: 7,041,604\n",
            "Trainable params: 6,957,956\n",
            "Non-trainable params: 83,648\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciVZLqD8rH2G",
        "colab_type": "code",
        "outputId": "e7afc274-1d9d-4458-84d5-5223ca1c8c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[lr_schedule],\n",
        "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                    validation_data=valid_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 1/20\n",
            "12/12 [==============================] - 67s 6s/step - loss: 1.6371 - categorical_accuracy: 0.1543 - val_loss: 1.8953 - val_categorical_accuracy: 0.0839 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 8.8e-05.\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 6s 530ms/step - loss: 0.9310 - categorical_accuracy: 0.6341 - val_loss: 2.2419 - val_categorical_accuracy: 0.3321 - lr: 8.8000e-05\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.000166.\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 6s 526ms/step - loss: 0.4021 - categorical_accuracy: 0.8665 - val_loss: 3.2537 - val_categorical_accuracy: 0.3431 - lr: 1.6600e-04\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.000244.\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 6s 527ms/step - loss: 0.2232 - categorical_accuracy: 0.9277 - val_loss: 3.5603 - val_categorical_accuracy: 0.3869 - lr: 2.4400e-04\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000322.\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 6s 526ms/step - loss: 0.1639 - categorical_accuracy: 0.9492 - val_loss: 2.5451 - val_categorical_accuracy: 0.4489 - lr: 3.2200e-04\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0004.\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 6s 523ms/step - loss: 0.0961 - categorical_accuracy: 0.9720 - val_loss: 0.9121 - val_categorical_accuracy: 0.6533 - lr: 4.0000e-04\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.000322.\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 6s 528ms/step - loss: 0.0956 - categorical_accuracy: 0.9727 - val_loss: 0.8299 - val_categorical_accuracy: 0.6971 - lr: 3.2200e-04\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0002596000000000001.\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 6s 525ms/step - loss: 0.0694 - categorical_accuracy: 0.9805 - val_loss: 0.6052 - val_categorical_accuracy: 0.7883 - lr: 2.5960e-04\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00020968000000000004.\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 7s 601ms/step - loss: 0.0552 - categorical_accuracy: 0.9844 - val_loss: 0.4440 - val_categorical_accuracy: 0.8394 - lr: 2.0968e-04\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00016974400000000002.\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 6s 531ms/step - loss: 0.0318 - categorical_accuracy: 0.9941 - val_loss: 0.3266 - val_categorical_accuracy: 0.9124 - lr: 1.6974e-04\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.00013779520000000003.\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 6s 527ms/step - loss: 0.0257 - categorical_accuracy: 0.9961 - val_loss: 0.3164 - val_categorical_accuracy: 0.9197 - lr: 1.3780e-04\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.00011223616000000004.\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 6s 536ms/step - loss: 0.0195 - categorical_accuracy: 0.9941 - val_loss: 0.3055 - val_categorical_accuracy: 0.9051 - lr: 1.1224e-04\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 9.178892800000003e-05.\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 6s 528ms/step - loss: 0.0156 - categorical_accuracy: 0.9974 - val_loss: 0.2355 - val_categorical_accuracy: 0.9416 - lr: 9.1789e-05\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 7.543114240000003e-05.\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 6s 531ms/step - loss: 0.0214 - categorical_accuracy: 0.9941 - val_loss: 0.1914 - val_categorical_accuracy: 0.9416 - lr: 7.5431e-05\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 6.234491392000002e-05.\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 6s 537ms/step - loss: 0.0166 - categorical_accuracy: 0.9961 - val_loss: 0.1857 - val_categorical_accuracy: 0.9453 - lr: 6.2345e-05\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 5.1875931136000024e-05.\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 6s 537ms/step - loss: 0.0213 - categorical_accuracy: 0.9941 - val_loss: 0.1914 - val_categorical_accuracy: 0.9453 - lr: 5.1876e-05\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 4.3500744908800015e-05.\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 6s 537ms/step - loss: 0.0148 - categorical_accuracy: 0.9980 - val_loss: 0.1616 - val_categorical_accuracy: 0.9599 - lr: 4.3501e-05\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 3.6800595927040014e-05.\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 6s 527ms/step - loss: 0.0213 - categorical_accuracy: 0.9935 - val_loss: 0.1325 - val_categorical_accuracy: 0.9635 - lr: 3.6801e-05\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 3.1440476741632015e-05.\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 6s 525ms/step - loss: 0.0100 - categorical_accuracy: 0.9993 - val_loss: 0.1224 - val_categorical_accuracy: 0.9708 - lr: 3.1440e-05\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 2.7152381393305616e-05.\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 6s 524ms/step - loss: 0.0116 - categorical_accuracy: 0.9987 - val_loss: 0.1202 - val_categorical_accuracy: 0.9672 - lr: 2.7152e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7APClASsX-0",
        "colab_type": "code",
        "outputId": "2d179d84-dcdb-40a5-d9fd-ed7792ac0de8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "with strategy.scope():\n",
        "    model2 = tf.keras.Sequential([efn.EfficientNetB7(input_shape=(256, 256, 3),\n",
        "                                             weights='imagenet',\n",
        "                                             include_top=False),\n",
        "                                 L.GlobalAveragePooling2D(),\n",
        "                                 L.Dense(train_labels.shape[1],\n",
        "                                         activation='softmax')])\n",
        "        \n",
        "    model2.compile(optimizer='adam',\n",
        "                  loss = 'categorical_crossentropy',\n",
        "                  metrics=['categorical_accuracy'])\n",
        "    model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnet-b7 (Model)      (None, 8, 8, 2560)        64097680  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2560)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 10244     \n",
            "=================================================================\n",
            "Total params: 64,107,924\n",
            "Trainable params: 63,797,204\n",
            "Non-trainable params: 310,720\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXTgv5AbsY5a",
        "colab_type": "code",
        "outputId": "9c77d586-cb09-4a5e-a8be-d7408e855bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        }
      },
      "source": [
        "history2 = model2.fit(train_dataset,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[lr_schedule],\n",
        "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                    validation_data=valid_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-686d7a40da5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     validation_data=valid_dataset)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 7 root error(s) found.\n  (0) Resource exhausted: {{function_node __inference_train_function_1100727}} Attempting to reserve 5.02G at the bottom of memory. That was not possible. There are 5.05G free, 0B reserved, and 4.89G reservable.\n\t [[{{node cluster_train_function/_execute_5_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: {{function_node __inference_train_function_1100727}} Attempting to reserve 5.02G at the bottom of memory. That was not possible. There are 5.05G free, 0B reserved, and 4.89G reservable.\n\t [[{{node cluster_train_function/_execute_4_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (2) Resource exhausted: {{function_node __inference_train_function_1100727}} Attempting to reserve 5.02G at the bottom of memory. That was not possible. There are 5.05G free, 0B reserved, and 4.89G reservable.\n\t [[{{node cluster_train_function/_execute_1_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (3) Resource exhausted: {{function_node __inference_train_function_1100727}} Attempting to reserve 5.02G at the bottom of memory. That was not possible. There are 5.05G free, 0B reserved, and 4.89G reservable.\n\t [[{{node cluster_train_function/_execute_6_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (4) Resource exhausted: {{function_node __inference_train_function_1100727}} Attempting to reserve 5.02G at the bottom of memory. That was not possible. There are 5.05G free, 0B reserved, and 4.89G reservable.\n\t [[{{node cluster_train_function/_execute_3_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (5) Resource exhausted: {{function_node __inference_train_function_1100727}} Attempting to reserve 5.02G at the bottom of memory. That was not possible. There are 5.05G free, 0B reserved, and 4.89G reservable.\n\t [[{{node cluster_train_function/_execute_2_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (6) Resource exhausted: {{function_node __inference_train_function_1100727}} Attempting to reserve 5.02G at the bottom of memory. That was not possible. There are 5.05G free, 0B reserved, and 4.89G reservable.\n\t [[{{node cluster_train_function/_execute_7_0}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n2 derived errors ignored."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyUclAezsX0L",
        "colab_type": "code",
        "outputId": "70af362b-b6e9-455c-8b11-eb394c48a64d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "probs_densenet = model.predict(test_dataset, verbose=1)\n",
        "sub.loc[:, 'healthy':] = probs_efnns\n",
        "sub.to_csv('submission_densenet.csv', index=False)\n",
        "sub.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 57s 4s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>healthy</th>\n",
              "      <th>multiple_diseases</th>\n",
              "      <th>rust</th>\n",
              "      <th>scab</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test_0</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>0.020581</td>\n",
              "      <td>9.790088e-01</td>\n",
              "      <td>0.000036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test_1</td>\n",
              "      <td>0.000309</td>\n",
              "      <td>0.012880</td>\n",
              "      <td>9.867858e-01</td>\n",
              "      <td>0.000025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test_2</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>7.594343e-08</td>\n",
              "      <td>0.999786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test_3</td>\n",
              "      <td>0.996548</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>3.394406e-03</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Test_4</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.001849</td>\n",
              "      <td>9.981177e-01</td>\n",
              "      <td>0.000031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id   healthy  multiple_diseases          rust      scab\n",
              "0   Test_0  0.000375           0.020581  9.790088e-01  0.000036\n",
              "1   Test_1  0.000309           0.012880  9.867858e-01  0.000025\n",
              "2   Test_2  0.000003           0.000212  7.594343e-08  0.999786\n",
              "3   Test_3  0.996548           0.000050  3.394406e-03  0.000007\n",
              "4   Test_4  0.000002           0.001849  9.981177e-01  0.000031"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JanSEbrRtlqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probs_efficientnet = model2.predict(test_dataset, verbose=1)\n",
        "sub.loc[:, 'healthy':] = probs_efficientnet\n",
        "sub.to_csv('submission_efficient.csv', index=False)\n",
        "sub.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cghbut0CwzlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('densenet121.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPrHKaSv1dfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_model=load_model('densenet121.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJP2Qh619mAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "imagePath='/content/appe-rust.jpg'\n",
        "imagePath2='/content/apple-rust2.jpg'\n",
        "imagePath3='/content/apple-scab.jpg'\n",
        "imagePath4='/content/apple-scab2.jpg'\n",
        "imagePath5='/content/images/Test_73.jpg'\n",
        "imagePath6='/content/apple-healthy.jpg'\n",
        "imagePath7='/content/apple-scab3.jpg'\n",
        "imagePath8='/content/apple-scab4.jpg'\n",
        "test_image = image.load_img(imagePath8, target_size = (512, 512)) \n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image1 = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "#predict the result\n",
        "result_classes= model.predict_classes(test_image1)\n",
        "result=model.predict_proba(test_image1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VITJ7q142DWO",
        "colab_type": "code",
        "outputId": "f4a53099-4ca5-4443-87f7-3d8e7ed4d210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"image=cv2.imread('/content/appe-rust.jpg')\n",
        "image=cv2.resize(image,(512,512))\n",
        "image=image.reshape(1,512,512,3)\n",
        "\n",
        "\n",
        "from google.colab.patches import cv2_imshow\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"image=cv2.imread('/content/appe-rust.jpg')\\nimage=cv2.resize(image,(512,512))\\nimage=image.reshape(1,512,512,3)\\n\\n\\nfrom google.colab.patches import cv2_imshow\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33KchCLXl8OW",
        "colab_type": "code",
        "outputId": "c66c3c08-4cd0-443c-f0fa-44fa000d1b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "result_classes, result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1]),\n",
              " array([[5.6240596e-31, 1.0000000e+00, 3.7499852e-09, 0.0000000e+00]],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwLxLMeGrnw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr4q_AQ1ypqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"./model.json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr3S9Y8Ayw5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkGpqEoczOYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}