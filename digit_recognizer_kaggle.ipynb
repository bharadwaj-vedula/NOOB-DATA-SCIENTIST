{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digit_recognizer_kaggle",
      "provenance": [],
      "authorship_tag": "ABX9TyMwV6M/k8U6lEOPAm+jnIuy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharadwaj-vedula/NOOB-DATA-SCIENTIST/blob/master/digit_recognizer_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AirEZ3eOw2HF",
        "colab_type": "code",
        "outputId": "304eb089-4377-4aa9-9e96-4cdbc443e6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "%tensorflow_version 2.x \n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "import pandas as pd \n",
        "from sklearn.model_selection import train_test_split \n",
        "from tensorflow import keras \n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Input "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiZ0UI91WR90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files \n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxfzE7kJWW2V",
        "colab_type": "code",
        "outputId": "3914cd92-e922-4807-cef9-437ba068ae39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6\n",
        "!kaggle -v\n",
        "!mkdir -p ~/.kaggle \n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling kaggle-1.5.6:\n",
            "  Successfully uninstalled kaggle-1.5.6\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/0c/d01aa759fdc501a58f431eb594a17495f15b88da142ce14b5845662c13f3/pip-20.0.2-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 5.0MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.0.2\n",
            "Collecting kaggle==1.5.6\n",
            "  Downloading kaggle-1.5.6.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2020.4.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.38.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.8)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-py3-none-any.whl size=72859 sha256=841dc38867eca54fccd85beea057dfc2ebd13ba8f83122e7d21e919c7c9cd0f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/3e/ff/77407ebac3ef71a79b9166a8382aecf88415a0bcbe3c095a01\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/api/kaggle_api_extended.py\", line 149, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV8cmf1mXGCI",
        "colab_type": "code",
        "outputId": "a96159e3-b791-432c-c9cd-f6d3c09fcaf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!kaggle competitions download -c digit-recognizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading digit-recognizer.zip to /content\n",
            "\r  0% 0.00/15.3M [00:00<?, ?B/s]\r 33% 5.00M/15.3M [00:00<00:00, 33.7MB/s]\r 59% 9.00M/15.3M [00:00<00:00, 34.3MB/s]\n",
            "\r100% 15.3M/15.3M [00:00<00:00, 55.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXoMh2DJXL1V",
        "colab_type": "code",
        "outputId": "e0e75693-6a36-471b-eed9-515c31d2ab61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name=\"digit-recognizer.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')\n",
        "\n",
        "\"\"\"from zipfile import ZipFile\n",
        "file_name=\"test.csv.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')\n",
        "\n",
        "from zipfile import ZipFile\n",
        "file_name=\"train.csv.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from zipfile import ZipFile\\nfile_name=\"test.csv.zip\"\\nwith ZipFile(file_name,\\'r\\') as zip:\\n  zip.extractall()\\n  print(\\'Done\\')\\n\\nfrom zipfile import ZipFile\\nfile_name=\"train.csv.zip\"\\nwith ZipFile(file_name,\\'r\\') as zip:\\n  zip.extractall()\\n  print(\\'Done\\')'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJdeuRDkYAcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train=pd.read_csv('train.csv')\n",
        "df_test=pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5z6624yYOpR",
        "colab_type": "code",
        "outputId": "274dc5ed-4b38-4edf-a0ea-d841e68ff5ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_train.shape,df_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((42000, 785), (28000, 784))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mTWwwuTYQak",
        "colab_type": "code",
        "outputId": "e68af68f-dcb4-429f-eefa-7f07ea1cc741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      1       0       0       0  ...         0         0         0         0\n",
              "1      0       0       0       0  ...         0         0         0         0\n",
              "2      1       0       0       0  ...         0         0         0         0\n",
              "3      4       0       0       0  ...         0         0         0         0\n",
              "4      0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsCjP2p6YvVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dummies=pd.get_dummies(df_train['label'],drop_first=False)\n",
        "df_train=pd.concat([df_train,label_dummies],copy=False,axis='columns')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxciXcPgZIG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.head()\n",
        "df_train=df_train.drop(['label'],axis='columns')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6mMhcb-wpDY",
        "colab_type": "code",
        "outputId": "f09a0707-4ab7-4140-ff02-4a8dc86309db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 794 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  ...  3  4  5  6  7  8  9\n",
              "0       0       0       0       0       0       0       0  ...  0  0  0  0  0  0  0\n",
              "1       0       0       0       0       0       0       0  ...  0  0  0  0  0  0  0\n",
              "2       0       0       0       0       0       0       0  ...  0  0  0  0  0  0  0\n",
              "3       0       0       0       0       0       0       0  ...  0  1  0  0  0  0  0\n",
              "4       0       0       0       0       0       0       0  ...  0  0  0  0  0  0  0\n",
              "\n",
              "[5 rows x 794 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFcElfpKxBa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=df_train.iloc[:,:784]\n",
        "y=df_train.iloc[:,784:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taay77AqxgWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=1,stratify=y,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uojKqUiexhWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalize \n",
        "X_train=X_train/255.0\n",
        "X_test=X_test/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFfeRJUpyscT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reshape \n",
        "X_train=X_train.values.reshape(-1,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Gquk1x2VNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=X_test.values.reshape(-1,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r_Gl8lx39Hz",
        "colab_type": "code",
        "outputId": "392b83da-dcf3-4709-a76d-d6ad75310f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.imshow(X_train[0][:,:,0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVzGO0I44ZA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm44U8bR4xbh",
        "colab_type": "code",
        "outputId": "74d56868-aaa2-481c-836e-6cc81eeee7bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model=keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(32,(5,5),activation='relu',padding='same',input_shape=(28,28,1)))\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "model.add(keras.layers.Conv2D(32,(5,5),padding='same',activation='relu'))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(keras.layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "model.add(keras.layers.Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "model.add(keras.layers.Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(256,activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))\n",
        "\n",
        "\n",
        "\"\"\"model.add(keras.layers.Conv2D(256,(3,3),activation='relu'))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "model.add(keras.layers.Dropout(0.5))\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"model.add(keras.layers.Conv2D(256,(3,3),activation='relu'))\\nmodel.add(keras.layers.MaxPool2D(2,2))\\nmodel.add(keras.layers.Dropout(0.5))\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44jEMjXFAAye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkK2Yf6bC4ls",
        "colab_type": "code",
        "outputId": "5efa8ed4-abe9-40d4-b2f7-1361b9f5bf22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        25632     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               803072    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 887,530\n",
            "Trainable params: 887,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MqlwKezC87r",
        "colab_type": "code",
        "outputId": "da839336-000f-4b0a-bf22-68468aea5575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "history=model.fit(X_train,y_train,batch_size=128,epochs=2,validation_data=(X_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "263/263 [==============================] - 3s 10ms/step - loss: 0.3373 - accuracy: 0.8898 - val_loss: 0.0799 - val_accuracy: 0.9750\n",
            "Epoch 2/2\n",
            "263/263 [==============================] - 2s 9ms/step - loss: 0.0904 - accuracy: 0.9737 - val_loss: 0.0596 - val_accuracy: 0.9824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFGudRUdHOAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test1=pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdIAhxsNEbSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test1=df_test1/255.0\n",
        "df_test1=df_test1.values.reshape(-1,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lY8LuInHS4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TrFULB-FzWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=model.predict(df_test1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj9JmczvIgFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_sub=[]\n",
        "for i in range(len(df_test1)):\n",
        "  y_sub.append(y_pred[i].argmax())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29g9XIlmIr4S",
        "colab_type": "code",
        "outputId": "fa38f24d-64e0-4a7c-dd38-04fa12717d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_sub"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2,\n",
              " 0,\n",
              " 9,\n",
              " 9,\n",
              " 3,\n",
              " 7,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 5,\n",
              " 7,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 9,\n",
              " 0,\n",
              " 9,\n",
              " 1,\n",
              " 1,\n",
              " 5,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 4,\n",
              " 7,\n",
              " 7,\n",
              " 5,\n",
              " 4,\n",
              " 2,\n",
              " 6,\n",
              " 2,\n",
              " 5,\n",
              " 5,\n",
              " 1,\n",
              " 6,\n",
              " 7,\n",
              " 7,\n",
              " 4,\n",
              " 9,\n",
              " 8,\n",
              " 7,\n",
              " 8,\n",
              " 2,\n",
              " 6,\n",
              " 7,\n",
              " 6,\n",
              " 8,\n",
              " 8,\n",
              " 3,\n",
              " 8,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 4,\n",
              " 1,\n",
              " 7,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 9,\n",
              " 0,\n",
              " 1,\n",
              " 6,\n",
              " 5,\n",
              " 8,\n",
              " 8,\n",
              " 2,\n",
              " 8,\n",
              " 9,\n",
              " 9,\n",
              " 2,\n",
              " 3,\n",
              " 5,\n",
              " 4,\n",
              " 1,\n",
              " 0,\n",
              " 9,\n",
              " 2,\n",
              " 4,\n",
              " 3,\n",
              " 6,\n",
              " 7,\n",
              " 2,\n",
              " 0,\n",
              " 6,\n",
              " 6,\n",
              " 1,\n",
              " 4,\n",
              " 3,\n",
              " 9,\n",
              " 7,\n",
              " 4,\n",
              " 0,\n",
              " 9,\n",
              " 2,\n",
              " 0,\n",
              " 7,\n",
              " 3,\n",
              " 0,\n",
              " 5,\n",
              " 0,\n",
              " 9,\n",
              " 0,\n",
              " 0,\n",
              " 4,\n",
              " 7,\n",
              " 1,\n",
              " 7,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 7,\n",
              " 2,\n",
              " 8,\n",
              " 6,\n",
              " 3,\n",
              " 8,\n",
              " 7,\n",
              " 8,\n",
              " 4,\n",
              " 3,\n",
              " 5,\n",
              " 6,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 5,\n",
              " 6,\n",
              " 4,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 5,\n",
              " 8,\n",
              " 7,\n",
              " 7,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 3,\n",
              " 5,\n",
              " 6,\n",
              " 5,\n",
              " 3,\n",
              " 7,\n",
              " 5,\n",
              " 7,\n",
              " 8,\n",
              " 3,\n",
              " 0,\n",
              " 4,\n",
              " 5,\n",
              " 1,\n",
              " 2,\n",
              " 7,\n",
              " 6,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 7,\n",
              " 8,\n",
              " 6,\n",
              " 1,\n",
              " 3,\n",
              " 7,\n",
              " 4,\n",
              " 1,\n",
              " 2,\n",
              " 4,\n",
              " 8,\n",
              " 5,\n",
              " 2,\n",
              " 4,\n",
              " 9,\n",
              " 2,\n",
              " 1,\n",
              " 6,\n",
              " 0,\n",
              " 6,\n",
              " 1,\n",
              " 4,\n",
              " 9,\n",
              " 6,\n",
              " 0,\n",
              " 9,\n",
              " 7,\n",
              " 6,\n",
              " 9,\n",
              " 1,\n",
              " 9,\n",
              " 0,\n",
              " 9,\n",
              " 9,\n",
              " 0,\n",
              " 8,\n",
              " 4,\n",
              " 6,\n",
              " 2,\n",
              " 0,\n",
              " 9,\n",
              " 3,\n",
              " 6,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 6,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 4,\n",
              " 6,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 4,\n",
              " 9,\n",
              " 1,\n",
              " 7,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 8,\n",
              " 6,\n",
              " 8,\n",
              " 6,\n",
              " 2,\n",
              " 8,\n",
              " 5,\n",
              " 5,\n",
              " 4,\n",
              " 8,\n",
              " 3,\n",
              " 5,\n",
              " 9,\n",
              " 7,\n",
              " 1,\n",
              " 3,\n",
              " 8,\n",
              " 4,\n",
              " 5,\n",
              " 1,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 3,\n",
              " 3,\n",
              " 5,\n",
              " 7,\n",
              " 0,\n",
              " 6,\n",
              " 8,\n",
              " 3,\n",
              " 1,\n",
              " 6,\n",
              " 0,\n",
              " 6,\n",
              " 3,\n",
              " 9,\n",
              " 5,\n",
              " 1,\n",
              " 5,\n",
              " 8,\n",
              " 4,\n",
              " 0,\n",
              " 9,\n",
              " 2,\n",
              " 0,\n",
              " 5,\n",
              " 3,\n",
              " 7,\n",
              " 1,\n",
              " 9,\n",
              " 9,\n",
              " 5,\n",
              " 7,\n",
              " 7,\n",
              " 9,\n",
              " 9,\n",
              " 6,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 6,\n",
              " 9,\n",
              " 8,\n",
              " 2,\n",
              " 6,\n",
              " 3,\n",
              " 7,\n",
              " 1,\n",
              " 4,\n",
              " 5,\n",
              " 8,\n",
              " 5,\n",
              " 9,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 8,\n",
              " 4,\n",
              " 1,\n",
              " 8,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 9,\n",
              " 8,\n",
              " 4,\n",
              " 5,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 6,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 9,\n",
              " 0,\n",
              " 0,\n",
              " 6,\n",
              " 0,\n",
              " 6,\n",
              " 3,\n",
              " 1,\n",
              " 8,\n",
              " 6,\n",
              " 0,\n",
              " 6,\n",
              " 5,\n",
              " 2,\n",
              " 2,\n",
              " 6,\n",
              " 7,\n",
              " 7,\n",
              " 2,\n",
              " 5,\n",
              " 8,\n",
              " 3,\n",
              " 9,\n",
              " 2,\n",
              " 7,\n",
              " 8,\n",
              " 6,\n",
              " 3,\n",
              " 8,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 8,\n",
              " 1,\n",
              " 6,\n",
              " 4,\n",
              " 8,\n",
              " 7,\n",
              " 9,\n",
              " 7,\n",
              " 6,\n",
              " 9,\n",
              " 5,\n",
              " 3,\n",
              " 7,\n",
              " 6,\n",
              " 5,\n",
              " 5,\n",
              " 4,\n",
              " 2,\n",
              " 6,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 7,\n",
              " 1,\n",
              " 7,\n",
              " 9,\n",
              " 9,\n",
              " 6,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 7,\n",
              " 3,\n",
              " 9,\n",
              " 7,\n",
              " 6,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 9,\n",
              " 3,\n",
              " 8,\n",
              " 6,\n",
              " 5,\n",
              " 0,\n",
              " 4,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 5,\n",
              " 9,\n",
              " 6,\n",
              " 6,\n",
              " 5,\n",
              " 3,\n",
              " 1,\n",
              " 4,\n",
              " 7,\n",
              " 4,\n",
              " 7,\n",
              " 4,\n",
              " 8,\n",
              " 5,\n",
              " 2,\n",
              " 6,\n",
              " 1,\n",
              " 3,\n",
              " 9,\n",
              " 5,\n",
              " 0,\n",
              " 8,\n",
              " 4,\n",
              " 7,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 9,\n",
              " 9,\n",
              " 7,\n",
              " 6,\n",
              " 9,\n",
              " 5,\n",
              " 9,\n",
              " 2,\n",
              " 3,\n",
              " 5,\n",
              " 6,\n",
              " 6,\n",
              " 7,\n",
              " 5,\n",
              " 0,\n",
              " 5,\n",
              " 1,\n",
              " 7,\n",
              " 4,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 4,\n",
              " 9,\n",
              " 5,\n",
              " 6,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 4,\n",
              " 8,\n",
              " 1,\n",
              " 2,\n",
              " 7,\n",
              " 9,\n",
              " 4,\n",
              " 8,\n",
              " 3,\n",
              " 7,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 4,\n",
              " 6,\n",
              " 7,\n",
              " 6,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 6,\n",
              " 5,\n",
              " 9,\n",
              " 4,\n",
              " 1,\n",
              " 8,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 8,\n",
              " 7,\n",
              " 5,\n",
              " 3,\n",
              " 5,\n",
              " 7,\n",
              " 4,\n",
              " 3,\n",
              " 6,\n",
              " 9,\n",
              " 0,\n",
              " 7,\n",
              " 7,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 7,\n",
              " 0,\n",
              " 5,\n",
              " 3,\n",
              " 8,\n",
              " 3,\n",
              " 5,\n",
              " 6,\n",
              " 5,\n",
              " 7,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 8,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 9,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 5,\n",
              " 5,\n",
              " 0,\n",
              " 7,\n",
              " 5,\n",
              " 6,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 8,\n",
              " 1,\n",
              " 6,\n",
              " 5,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 9,\n",
              " 6,\n",
              " 5,\n",
              " 3,\n",
              " 6,\n",
              " 0,\n",
              " 4,\n",
              " 8,\n",
              " 2,\n",
              " 4,\n",
              " 2,\n",
              " 5,\n",
              " 1,\n",
              " 7,\n",
              " 6,\n",
              " 9,\n",
              " 1,\n",
              " 7,\n",
              " 3,\n",
              " 8,\n",
              " 0,\n",
              " 8,\n",
              " 8,\n",
              " 4,\n",
              " 5,\n",
              " 3,\n",
              " 6,\n",
              " 6,\n",
              " 6,\n",
              " 0,\n",
              " 3,\n",
              " 5,\n",
              " 1,\n",
              " 7,\n",
              " 1,\n",
              " 6,\n",
              " 2,\n",
              " 8,\n",
              " 5,\n",
              " 6,\n",
              " 4,\n",
              " 7,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 4,\n",
              " 7,\n",
              " 0,\n",
              " 0,\n",
              " 9,\n",
              " 8,\n",
              " 5,\n",
              " 9,\n",
              " 4,\n",
              " 0,\n",
              " 8,\n",
              " 1,\n",
              " 5,\n",
              " 6,\n",
              " 2,\n",
              " 6,\n",
              " 1,\n",
              " 8,\n",
              " 6,\n",
              " 1,\n",
              " 4,\n",
              " 7,\n",
              " 7,\n",
              " 8,\n",
              " 3,\n",
              " 0,\n",
              " 9,\n",
              " 9,\n",
              " 6,\n",
              " 7,\n",
              " 7,\n",
              " 4,\n",
              " 4,\n",
              " 1,\n",
              " 8,\n",
              " 4,\n",
              " 8,\n",
              " 0,\n",
              " 2,\n",
              " 8,\n",
              " 2,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 7,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 8,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 6,\n",
              " 3,\n",
              " 9,\n",
              " 4,\n",
              " 3,\n",
              " 8,\n",
              " 7,\n",
              " 7,\n",
              " 2,\n",
              " 6,\n",
              " 0,\n",
              " 6,\n",
              " 9,\n",
              " 8,\n",
              " 8,\n",
              " 1,\n",
              " 3,\n",
              " 4,\n",
              " 6,\n",
              " 9,\n",
              " 9,\n",
              " 2,\n",
              " 6,\n",
              " 0,\n",
              " 1,\n",
              " 8,\n",
              " 4,\n",
              " 3,\n",
              " 9,\n",
              " 8,\n",
              " 8,\n",
              " 4,\n",
              " 0,\n",
              " 5,\n",
              " 0,\n",
              " 6,\n",
              " 0,\n",
              " 4,\n",
              " 4,\n",
              " 6,\n",
              " 5,\n",
              " 1,\n",
              " 8,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 6,\n",
              " 2,\n",
              " 3,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 6,\n",
              " 4,\n",
              " 7,\n",
              " 5,\n",
              " 7,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 7,\n",
              " 7,\n",
              " 1,\n",
              " 5,\n",
              " 1,\n",
              " 5,\n",
              " 4,\n",
              " 4,\n",
              " 3,\n",
              " 4,\n",
              " 3,\n",
              " 9,\n",
              " 0,\n",
              " 7,\n",
              " 8,\n",
              " 6,\n",
              " 4,\n",
              " 9,\n",
              " 4,\n",
              " 4,\n",
              " 1,\n",
              " 4,\n",
              " 7,\n",
              " 1,\n",
              " 1,\n",
              " 8,\n",
              " 7,\n",
              " 0,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 0,\n",
              " 0,\n",
              " 5,\n",
              " 1,\n",
              " 8,\n",
              " 6,\n",
              " 5,\n",
              " 0,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 4,\n",
              " 6,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 6,\n",
              " 9,\n",
              " 8,\n",
              " 3,\n",
              " 5,\n",
              " 5,\n",
              " 4,\n",
              " 8,\n",
              " 6,\n",
              " 5,\n",
              " 0,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 3,\n",
              " 1,\n",
              " 6,\n",
              " 9,\n",
              " 9,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 4,\n",
              " 9,\n",
              " 6,\n",
              " 9,\n",
              " 1,\n",
              " 5,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 4,\n",
              " 0,\n",
              " 9,\n",
              " 7,\n",
              " 4,\n",
              " 3,\n",
              " 0,\n",
              " 5,\n",
              " 0,\n",
              " 1,\n",
              " 9,\n",
              " 0,\n",
              " 4,\n",
              " 5,\n",
              " 2,\n",
              " 8,\n",
              " 8,\n",
              " 5,\n",
              " 9,\n",
              " 3,\n",
              " 9,\n",
              " 6,\n",
              " 1,\n",
              " 5,\n",
              " 5,\n",
              " 1,\n",
              " 9,\n",
              " 0,\n",
              " 8,\n",
              " 8,\n",
              " 6,\n",
              " 7,\n",
              " 2,\n",
              " 8,\n",
              " 5,\n",
              " 8,\n",
              " 9,\n",
              " 7,\n",
              " 7,\n",
              " 2,\n",
              " 8,\n",
              " 1,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 0,\n",
              " 4,\n",
              " 1,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 6,\n",
              " 9,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 4,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 4,\n",
              " 9,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 7,\n",
              " 1,\n",
              " 5,\n",
              " 4,\n",
              " 9,\n",
              " 1,\n",
              " 7,\n",
              " 6,\n",
              " 0,\n",
              " 4,\n",
              " 2,\n",
              " 9,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 5,\n",
              " 7,\n",
              " 4,\n",
              " 7,\n",
              " 8,\n",
              " 3,\n",
              " 2,\n",
              " 7,\n",
              " 2,\n",
              " 0,\n",
              " 4,\n",
              " 7,\n",
              " 1,\n",
              " 6,\n",
              " 4,\n",
              " 6,\n",
              " 1,\n",
              " 5,\n",
              " 7,\n",
              " 3,\n",
              " 5,\n",
              " 9,\n",
              " 4,\n",
              " 7,\n",
              " 9,\n",
              " 6,\n",
              " 6,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 4,\n",
              " 5,\n",
              " 3,\n",
              " 7,\n",
              " 7,\n",
              " 9,\n",
              " 5,\n",
              " 6,\n",
              " 2,\n",
              " 6,\n",
              " 1,\n",
              " 0,\n",
              " 9,\n",
              " 3,\n",
              " 2,\n",
              " 9,\n",
              " 2,\n",
              " 6,\n",
              " 7,\n",
              " 5,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 8,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 7,\n",
              " 9,\n",
              " 4,\n",
              " 0,\n",
              " 9,\n",
              " 5,\n",
              " 1,\n",
              " 8,\n",
              " 8,\n",
              " 5,\n",
              " 3,\n",
              " 2,\n",
              " 9,\n",
              " 6,\n",
              " 7,\n",
              " 0,\n",
              " 8,\n",
              " 0,\n",
              " 7,\n",
              " 4,\n",
              " 5,\n",
              " 8,\n",
              " 7,\n",
              " 9,\n",
              " 7,\n",
              " 7,\n",
              " 0,\n",
              " 5,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 9,\n",
              " 0,\n",
              " 6,\n",
              " 8,\n",
              " 3,\n",
              " 6,\n",
              " 2,\n",
              " 2,\n",
              " 9,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfik5INWGQRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission=pd.DataFrame({'ImageId':[i for i in range(len(df_test1))],'Label':y_sub})\n",
        "submission.to_csv('submission.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m8gy2gUKfXR",
        "colab_type": "code",
        "outputId": "745f90d1-3e59-4e93-ce4d-bb3fb57ff3a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "submission.head(),len(submission)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   ImageId  Label\n",
              " 0        0      2\n",
              " 1        1      0\n",
              " 2        2      9\n",
              " 3        3      9\n",
              " 4        4      3, 28000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLUwAJXsGSGl",
        "colab_type": "code",
        "outputId": "e1b15975-3811-4df8-d33c-ee3e0e096859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred[0].argmax()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w8OOtFCIKyH",
        "colab_type": "code",
        "outputId": "2d647e60-7911-4a60-aa81-fcdb86ce871b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(y_sub)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0gFTciRIWVN",
        "colab_type": "code",
        "outputId": "424f46ea-0df5-4b5d-9cd7-a24d4e2cb887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(df_test1[4][:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa6d16c2a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG0gJev7DMWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "new_input=keras.layers.Input(shape=(28,28,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vleh5dpYbkCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet_model=keras.applications.resnet50.ResNet50()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2RYKLyZbkFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBmoiJ4ccV1f",
        "colab_type": "code",
        "outputId": "b87c3cdd-dc8b-4ab5-95cf-31e0c71c297c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 25,636,712\n",
            "Trainable params: 25,583,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP9CM6bKcnAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_resnet_model=keras.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtFGLiMHdTlY",
        "colab_type": "code",
        "outputId": "2dae71c3-b73f-41ca-e49c-fae19253bcb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "for layer in resnet_model.layers:\n",
        "  seq_resnet_model.add(layer)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Sequential inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"sequential_3\" was not an Input tensor, it was generated by layer input_6.\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: input_6:0\n",
            "WARNING:tensorflow:Sequential inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"sequential_3\" was not an Input tensor, it was generated by layer input_6.\n",
            "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
            "The tensor that caused the issue was: input_6:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-1adf625a7614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mseq_resnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 886\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    887\u001b[0m         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\n\u001b[1;32m    888\u001b[0m             and self._supports_ragged_inputs is False):  # pylint: disable=g-bool-id-comparison\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;34m' incompatible with the layer: expected axis '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;34m' of input shape to have value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 ' but received input with shape ' + str(shape))\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv1_conv is incompatible with the layer: expected axis -1 of input shape to have value 3 but received input with shape [None, 62, 62, 256]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da1PWpwSdxse",
        "colab_type": "code",
        "outputId": "76fc2108-c65e-41f5-f6f0-b8911cda7b0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "seq_resnet_model.add(resnet_model.layers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-a9844e4b552a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseq_resnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    172\u001b[0m       raise TypeError('The added layer must be '\n\u001b[1;32m    173\u001b[0m                       \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                       'Found: ' + str(layer))\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: [<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fa6d278dfd0>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa6d27ac198>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa6d27ac588>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa6d27ac748>, <tensorflow.python.keras.layers.core.Activation object at 0x7fa6d27b2ac8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7fa6d27b21d0>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa6d2758c18>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa6d2765a90>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa6d270d908>, <tensorflow.python.keras.layers.core.Activation object at 0x7fa6d2713a58>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa6d2713048>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa6d2739d68>, <tensorflow.python.keras.layers.core.Activation object at 0x7fa6d273df28>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa6d275f1d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa6d273d6d8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7fa6d275fb00>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwlAgFNBfUF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_model=keras.applications.vgg16.VGG16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ90S-ncftRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_vgg16_model=keras.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yLxYoELf0GY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in vgg16_model.layers:\n",
        "  seq_vgg16_model.add(layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpEuRvs6gtjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_vgg16_model.pop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-Ryzszeg44s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in seq_vgg16_model.layers:\n",
        "  layer.trainable=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQQq87U-f7A-",
        "colab_type": "code",
        "outputId": "6d939eb7-b370-4d60-874d-dafd3c03c1e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "\n",
        "model2=keras.Sequential()\n",
        "model2.add(keras.layers.Conv2D(32,(5,5),activation='relu',padding='same',input_shape=(28,28,1)))\n",
        "model2.add(seq_vgg16_model)\n",
        "model2.add(keras.layers.Dense(10,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-bd971fe06463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_vgg16_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 886\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    887\u001b[0m         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\n\u001b[1;32m    888\u001b[0m             and self._supports_ragged_inputs is False):  # pylint: disable=g-bool-id-comparison\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;34m' incompatible with the layer: expected axis '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;34m' of input shape to have value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 ' but received input with shape ' + str(shape))\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer sequential_5 is incompatible with the layer: expected axis -1 of input shape to have value 3 but received input with shape [None, 28, 28, 32]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAbPMSWrhsjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}